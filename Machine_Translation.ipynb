{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###\n",
    "### change word start with '&apos' to are\n",
    "### preprocess token including delete null token\n",
    "def preposs_toekn(tokens):\n",
    "    return [token for token in tokens if token != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en_add = './iwsltzhen/iwslt-zh-en/train.tok.en'\n",
    "train_zh_add = './iwsltzhen/iwslt-zh-en/train.tok.zh'\n",
    "val_en_add = './iwsltzhen/iwslt-zh-en/dev.tok.en'\n",
    "val_zh_add = './iwsltzhen/iwslt-zh-en/dev.tok.zh'\n",
    "\n",
    "train_en = []\n",
    "with open(train_en_add) as f:\n",
    "    for line in f:\n",
    "        train_en.append(preposs_toekn(line[:-1].strip().split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_zh = []\n",
    "with open(train_zh_add) as f:\n",
    "    for line in f:\n",
    "        train_zh.append(preposs_toekn(line[:-1].strip().split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Life', 'in', 'the', 'deep', 'oceans']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_en[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "UNK_token = 2\n",
    "\n",
    "def read_embedding(fasttest_home = './wiki-news-300d-1M.vec'):\n",
    "    words_to_load = 50000\n",
    "\n",
    "    words_ft = {}\n",
    "    idx2words_ft = {}\n",
    "        \n",
    "    SOS_token = 0\n",
    "    words_ft['$SOS$'] = SOS_token\n",
    "    idx2words_ft[SOS_token] = '$SOS$'\n",
    "    EOS_token = 1\n",
    "    words_ft['$EOS$'] = EOS_token\n",
    "    idx2words_ft[EOS_token] = '$EOS$'\n",
    "    Unk_token = 2\n",
    "    words_ft['$UNK$'] = Unk_token\n",
    "    idx2words_ft[Unk_token] = '$UNK$'\n",
    "    \n",
    "    with open(fasttest_home) as f:\n",
    "        loaded_embeddings_ft = np.zeros((words_to_load, 300)) \n",
    "        ordered_words_ft = []\n",
    "        for i, line in enumerate(f):\n",
    "            i = i+3\n",
    "            if i >= words_to_load: \n",
    "                break\n",
    "            s = line.split()\n",
    "            loaded_embeddings_ft[i, :] = np.asarray(s[1:])\n",
    "            words_ft[s[0]] = i\n",
    "            idx2words_ft[i] = s[0]\n",
    "            ordered_words_ft.append(s[0])\n",
    "    \n",
    "    return words_ft,idx2words_ft,loaded_embeddings_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words_ft,idx2words_ft = read_embedding(fasttest_home = './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "UNK_token = 2\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"$SOS$\" : 0, \"$EOS$\" : 1, \"$UNK$\" : 2}\n",
    "        self.word2count = {\"$SOS$\" : 0, \"$EOS$\" : 0, \"$UNK$\" : 0}\n",
    "        self.index2word = {0: \"$SOS$\", 1: \"$EOS$\", 2: \"$UNK$\"}\n",
    "        self.n_words = 3  # Count SOS and EOS\n",
    "        self.embedding_matrix = None\n",
    "\n",
    "#     def addSentence(self, sentence):\n",
    "#         for word in sentence.split(' '):\n",
    "#             self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    def load_embedding(self,address = './'):\n",
    "        self.word2index, self.index2word,self.embedding_matrix = read_embedding(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2index(data,word2index):\n",
    "    indexdata = []\n",
    "    for line in data:\n",
    "        indexdata.append([word2index[c] if c in word2index.keys() else UNK_token  for c in line])\n",
    "        indexdata[-1].append(EOS_token)\n",
    "    print('finish')\n",
    "    return indexdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparelang(name,data):\n",
    "    lang = Lang(name)\n",
    "    for line in data:\n",
    "        for word in line:\n",
    "            lang.addWord(word)\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# enLang = Lang('eng')\n",
    "# enLang.load_embedding('/scratch/tw1682/NLP/wiki-news-300d-1M.vec')\n",
    "enLang = preparelang('en',train_en)\n",
    "zhLang = preparelang('zh',train_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "train_input_index = text2index(train_en,enLang.word2index)\n",
    "train_output_index = text2index(train_zh,zhLang.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ Data Loader #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_input, train_ouput):\n",
    "        \"\"\"\n",
    "        @param data_list: list of character\n",
    "        @param target_list: list of targets\n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list, self.target_list = train_input, train_ouput\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "        #self.word2index = word2index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        train = self.data_list[key]\n",
    "        label = self.target_list[key]\n",
    "        train_length = len(train)\n",
    "        label_length = len(label)\n",
    "        \n",
    "        return train,train_length,label,label_length\n",
    "\n",
    "def vocab_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all\n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    train_length_list = []\n",
    "    label_length_list = []\n",
    "\n",
    "    for datum in batch:\n",
    "        label_length_list.append(datum[3])\n",
    "        train_length_list.append(datum[1])\n",
    "    \n",
    "    batch_max_input_length = np.max(train_length_list)\n",
    "    batch_max_output_length = np.max(label_length_list)\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]),\n",
    "                                pad_width=((0,batch_max_input_length-datum[1])),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "        \n",
    "        padded_vec = np.pad(np.array(datum[2]),\n",
    "                                pad_width=((0,batch_max_output_length-datum[3])),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        label_list.append(padded_vec)\n",
    "        \n",
    "    ind_dec_order = np.argsort(train_length_list)[::-1]\n",
    "    data_list = np.array(data_list)[ind_dec_order]\n",
    "    train_length_list = np.array(train_length_list)[ind_dec_order]\n",
    "    label_list = np.array(label_list)[ind_dec_order]\n",
    "    label_length_list = np.array(label_length_list)[ind_dec_order]\n",
    "    \n",
    "    #print(type(np.array(data_list)),type(np.array(label_list)))\n",
    "    \n",
    "    return [torch.from_numpy(np.array(data_list)).to(device), \n",
    "            torch.LongTensor(train_length_list).to(device), \n",
    "            torch.from_numpy(np.array(label_list)).to(device), \n",
    "            torch.LongTensor(label_length_list).to(device)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build train, valid and test dataloaders\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "\n",
    "train_dataset = VocabDataset(train_input_index,train_output_index)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=BATCH_SIZE,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=False)\n",
    "\n",
    "# val_dataset = VocabDataset(val_data)\n",
    "# val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "#                                            batch_size=BATCH_SIZE,\n",
    "#                                            collate_fn=vocab_collate_func,\n",
    "#                                            shuffle=True)\n",
    "\n",
    "# test_dataset = VocabDataset(test_data)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "#                                            batch_size=BATCH_SIZE,\n",
    "#                                            collate_fn=vocab_collate_func,\n",
    "#                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 6])\n",
      "tensor([6], device='cuda:0')\n",
      "torch.Size([1, 7])\n",
      "tensor([7], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for data, data_lengths, labels, label_lengths in train_loader:\n",
    "    print(data.shape)\n",
    "    print(data_lengths)\n",
    "    print(labels.shape)\n",
    "    print(label_lengths)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_direction):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_direction = num_direction\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        if num_direction == 1:\n",
    "            self.gru = nn.GRU(embed_size, hidden_size, batch_first=True)\n",
    "        elif num_direction == 2:\n",
    "            self.gru = nn.GRU(embed_size, hidden_size, batch_first=True, bidirectional = True)\n",
    "        else:\n",
    "            print('number of direction out of bound')\n",
    "\n",
    "    def forward(self, x, hidden, lengths):\n",
    "        embed = self.embedding(x) #.view(1, 1, -1)\n",
    "        embed = torch.nn.utils.rnn.pack_padded_sequence(embed, lengths.cpu().numpy(), batch_first=True)\n",
    "        rnn_out, hidden = self.gru(embed, hidden)\n",
    "        rnn_out, _ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out, batch_first=True)\n",
    "        return rnn_out, hidden\n",
    "\n",
    "    def initHidden(self,batch_size):\n",
    "        hidden = torch.randn(self.num_direction, batch_size, self.hidden_size, device=device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        #output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[:,0,:]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def indexesFromSentence(lang, sentence):\n",
    "#     return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "# def tensorFromSentence(lang, sentence):\n",
    "#     indexes = indexesFromSentence(lang, sentence)\n",
    "#     indexes.append(EOS_token)\n",
    "#     return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "# def tensorsFromPair(pair):\n",
    "#     input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "#     target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "#     return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0\n",
    "MAX_LENGTH = 50\n",
    "\n",
    "def train(input_tensor, input_tensor_length, target_tensor, encoder, decoder, \n",
    "          encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "\n",
    "    encoder_hidden = encoder.initHidden(BATCH_SIZE).to(device)\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    #input_length = input_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "#     for ei in range(input_length):\n",
    "#         encoder_output, encoder_hidden = encoder(\n",
    "#             input_tensor[ei], encoder_hidden,input_tensor_length)\n",
    "#         encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    ########################bug here######################\n",
    "    ########################bug here######################\n",
    "    ########################bug here######################\n",
    "    ########################bug here######################\n",
    "    encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden, input_tensor_length)\n",
    "\n",
    "    # target_tensor = \n",
    "    target_length = target_tensor.size(1)\n",
    "    \n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[:, di])\n",
    "            decoder_input = target_tensor[:,di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "            \n",
    "            loss += criterion(decoder_output, target_tensor[:,di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(loader, encoder, decoder, n_iters = 340000, print_every=1000, \n",
    "               plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    n_iter = 0\n",
    "    \n",
    "    for data, data_lengths, labels, label_lengths in train_loader:\n",
    "        n_iter += 1\n",
    "        input_tensor, target_tensor = data, labels\n",
    "        loss = train(input_tensor, data_lengths, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if n_iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('(%d %d%%) %.4f' % (n_iter, n_iter / n_iter * 100, print_loss_avg))\n",
    "\n",
    "        if n_iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import math\n",
    "\n",
    "\n",
    "# def asMinutes(s):\n",
    "#     m = math.floor(s / 60)\n",
    "#     s -= m * 60\n",
    "#     return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "# def timeSince(since, percent):\n",
    "#     now = time.time()\n",
    "#     s = now - since\n",
    "#     es = s / (percent)\n",
    "#     rs = es - s\n",
    "#     return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000 100%) 4.4443\n",
      "(2000 100%) 4.1372\n",
      "(3000 100%) 4.0508\n",
      "(4000 100%) 4.1120\n",
      "(5000 100%) 4.0000\n",
      "(6000 100%) 3.8409\n",
      "(7000 100%) 4.0017\n",
      "(8000 100%) 3.6553\n",
      "(9000 100%) 4.0510\n",
      "(10000 100%) 4.2547\n",
      "(11000 100%) 4.1068\n",
      "(12000 100%) 4.3577\n",
      "(13000 100%) 4.1968\n",
      "(14000 100%) 4.3973\n",
      "(15000 100%) 4.4362\n",
      "(16000 100%) 4.7411\n",
      "(17000 100%) 4.9029\n",
      "(18000 100%) 4.9494\n",
      "(19000 100%) 4.7856\n",
      "(20000 100%) 5.2124\n",
      "(21000 100%) 4.9777\n",
      "(22000 100%) 5.2128\n",
      "(23000 100%) 5.0632\n",
      "(24000 100%) 4.9350\n",
      "(25000 100%) 4.9321\n",
      "(26000 100%) 4.9340\n",
      "(27000 100%) 5.2176\n",
      "(28000 100%) 5.1690\n",
      "(29000 100%) 5.1879\n",
      "(30000 100%) 5.0359\n",
      "(31000 100%) 5.0546\n",
      "(32000 100%) 4.9774\n",
      "(33000 100%) 5.0609\n",
      "(34000 100%) 5.1237\n",
      "(35000 100%) 5.0409\n",
      "(36000 100%) 4.9743\n",
      "(37000 100%) 4.9552\n",
      "(38000 100%) 4.9755\n",
      "(39000 100%) 5.0587\n",
      "(40000 100%) 5.1272\n",
      "(41000 100%) 5.1067\n",
      "(42000 100%) 5.1972\n",
      "(43000 100%) 5.0666\n",
      "(44000 100%) 4.6984\n",
      "(45000 100%) 4.9817\n",
      "(46000 100%) 4.9396\n",
      "(47000 100%) 5.0043\n",
      "(48000 100%) 5.0896\n",
      "(49000 100%) 5.1401\n",
      "(50000 100%) 4.9943\n",
      "(51000 100%) 4.9529\n",
      "(52000 100%) 5.1188\n",
      "(53000 100%) 4.9927\n",
      "(54000 100%) 4.9221\n",
      "(55000 100%) 4.9391\n",
      "(56000 100%) 5.0149\n",
      "(57000 100%) 4.9879\n",
      "(58000 100%) 5.1765\n",
      "(59000 100%) 5.1592\n",
      "(60000 100%) 5.0592\n",
      "(61000 100%) 5.3598\n",
      "(62000 100%) 4.9478\n",
      "(63000 100%) 5.0448\n",
      "(64000 100%) 4.9570\n",
      "(65000 100%) 4.9414\n",
      "(66000 100%) 5.0790\n",
      "(67000 100%) 5.1646\n",
      "(68000 100%) 4.9320\n",
      "(69000 100%) 4.9134\n",
      "(70000 100%) 5.0039\n",
      "(71000 100%) 4.9696\n",
      "(72000 100%) 4.8781\n",
      "(73000 100%) 5.1517\n",
      "(74000 100%) 5.1693\n",
      "(75000 100%) 4.9367\n",
      "(76000 100%) 5.1022\n",
      "(77000 100%) 5.1182\n",
      "(78000 100%) 5.1939\n",
      "(79000 100%) 5.1511\n"
     ]
    }
   ],
   "source": [
    "input_size = enLang.n_words\n",
    "emb_size = 300\n",
    "hidden_size = 100\n",
    "num_direction = 1\n",
    "output_size = zhLang.n_words\n",
    "encoder = EncoderRNN(input_size, emb_size,hidden_size,num_direction = 1).to(device)\n",
    "decoder = DecoderRNN(hidden_size, output_size).to(device)\n",
    "trainIters(train_loader,encoder, decoder, 3, print_every=1000, plot_every=100, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1,2,3],[2,3]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 2, 3]), list([2, 3])], dtype=object)"
      ]
     },
     "execution_count": 269,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
