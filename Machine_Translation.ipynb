{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import time\n",
    "import os.path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_packed_sequence, pack_padded_sequence\n",
    "\n",
    "import random\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "### change word start with '&apos' to are\n",
    "### preprocess token including delete null token\n",
    "def preposs_toekn(tokens):\n",
    "    return [token for token in tokens if token != '']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en_add = './iwsltzhen/iwslt-zh-en/train.tok.en'\n",
    "train_zh_add = './iwsltzhen/iwslt-zh-en/train.tok.zh'\n",
    "val_en_add = './iwsltzhen/iwslt-zh-en/dev.tok.en'\n",
    "val_zh_add = './iwsltzhen/iwslt-zh-en/dev.tok.zh'\n",
    "\n",
    "train_en = []\n",
    "with open(train_en_add) as f:\n",
    "    for line in f:\n",
    "        train_en.append(preposs_toekn(line[:-1].strip().split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_en = []\n",
    "with open(val_en_add) as f:\n",
    "    for line in f:\n",
    "        train_en.append(preposs_toekn(line[:-1].strip().split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1261"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_en)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_zh = []\n",
    "with open(train_zh_add) as f:\n",
    "    for line in f:\n",
    "        train_zh.append(preposs_toekn(line[:-1].strip().split(' ')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Life', 'in', 'the', 'deep', 'oceans']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_en[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#words_ft,idx2words_ft = read_embedding(fasttest_home = './')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0\n",
    "SOS_token = 1\n",
    "EOS_token = 2\n",
    "UNK_token = 3\n",
    "\n",
    "def read_embedding(fasttest_home = './wiki-news-300d-1M.vec'):\n",
    "    words_to_load = 50000\n",
    "\n",
    "    words_ft = {}\n",
    "    idx2words_ft = {}\n",
    "    \n",
    "    words_ft['$PAD$'] = PAD_token\n",
    "    idx2words_ft[PAD_token] = '$PAD$'\n",
    "    words_ft['$SOS$'] = SOS_token\n",
    "    idx2words_ft[SOS_token] = '$SOS$'\n",
    "    words_ft['$EOS$'] = EOS_token\n",
    "    idx2words_ft[EOS_token] = '$EOS$'\n",
    "    words_ft['$UNK$'] = UNK_token\n",
    "    idx2words_ft[UNK_token] = '$UNK$'\n",
    "    \n",
    "    with open(fasttest_home) as f:\n",
    "        loaded_embeddings_ft = np.zeros((words_to_load, 300)) \n",
    "        ordered_words_ft = []\n",
    "        f.readline()\n",
    "        for i, line in enumerate(f):\n",
    "            i = i+4\n",
    "            if i >= words_to_load: \n",
    "                break\n",
    "            s = line.split()\n",
    "            try:\n",
    "                loaded_embeddings_ft[i, :] = np.asarray(s[1:])\n",
    "            except:\n",
    "                print('')\n",
    "                \n",
    "            words_ft[s[0]] = i\n",
    "            idx2words_ft[i] = s[0]\n",
    "            ordered_words_ft.append(s[0])\n",
    "    \n",
    "    return words_ft,idx2words_ft,loaded_embeddings_ft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {\"PAD\" : PAD_token,\"$SOS$\" : SOS_token, \"$EOS$\" : EOS_token, \"$UNK$\" : UNK_token}\n",
    "        self.word2count = {\"PAD\" : 0, \"$SOS$\" : 0, \"$EOS$\" : 0, \"$UNK$\" : 0}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"$SOS$\", EOS_token: \"$EOS$\", UNK_token: \"$UNK$\"}\n",
    "        self.n_words = 3  # Count SOS and EOS\n",
    "        self.embedding_matrix = None\n",
    "\n",
    "#     def addSentence(self, sentence):\n",
    "#         for word in sentence.split(' '):\n",
    "#             self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1\n",
    "    \n",
    "    def load_embedding(self,address = './'):\n",
    "        self.word2index, self.index2word,self.embedding_matrix = read_embedding(address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text2index(data,word2index):\n",
    "    indexdata = []\n",
    "    for line in data:\n",
    "        indexdata.append([word2index[c] if c in word2index.keys() else UNK_token  for c in line])\n",
    "        indexdata[-1].append(EOS_token)\n",
    "    print('finish')\n",
    "    return indexdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparelang(name,data):\n",
    "    lang = Lang(name)\n",
    "    for line in data:\n",
    "        for word in line:\n",
    "            lang.addWord(word)\n",
    "    return lang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "enLang = Lang('en')\n",
    "enLang.load_embedding('/scratch/tw1682/embedding/wiki.en.vec')\n",
    "zhLang = Lang('zh')\n",
    "zhLang.load_embedding('/scratch/tw1682/embedding/wiki.zh.vec')\n",
    "#enLang = preparelang('en',train_en)\n",
    "#zhLang = preparelang('zh',train_zh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "train_input_index = text2index(train_en,enLang.word2index)\n",
    "train_output_index = text2index(train_zh,zhLang.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "50000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-c01841c26583>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0menLang\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex2word\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m50000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 50000"
     ]
    }
   ],
   "source": [
    "enLang.index2word[50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enLang.n_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish\n",
      "finish\n"
     ]
    }
   ],
   "source": [
    "train_input_index = text2index(train_en,enLang.word2index)\n",
    "train_output_index = text2index(train_zh,zhLang.word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ Data Loader #########################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VocabDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Class that represents a train/validation/test dataset that's readable for PyTorch\n",
    "    Note that this class inherits torch.utils.data.Dataset\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, train_input, train_ouput):\n",
    "        \"\"\"\n",
    "        @param data_list: list of character\n",
    "        @param target_list: list of targets\n",
    "\n",
    "        \"\"\"\n",
    "        self.data_list, self.target_list = train_input, train_ouput\n",
    "        assert (len(self.data_list) == len(self.target_list))\n",
    "        #self.word2index = word2index\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        \"\"\"\n",
    "        Triggered when you call dataset[i]\n",
    "        \"\"\"\n",
    "        train = self.data_list[key]\n",
    "        label = self.target_list[key]\n",
    "        train_length = len(train)\n",
    "        label_length = len(label)\n",
    "        \n",
    "        return train,train_length,label,label_length\n",
    "\n",
    "def vocab_collate_func(batch):\n",
    "    \"\"\"\n",
    "    Customized function for DataLoader that dynamically pads the batch so that all\n",
    "    data have the same length\n",
    "    \"\"\"\n",
    "    data_list = []\n",
    "    label_list = []\n",
    "    train_length_list = []\n",
    "    label_length_list = []\n",
    "\n",
    "    for datum in batch:\n",
    "        label_length_list.append(datum[3])\n",
    "        train_length_list.append(datum[1])\n",
    "    \n",
    "    batch_max_input_length = np.max(train_length_list)\n",
    "    batch_max_output_length = np.max(label_length_list)\n",
    "    # padding\n",
    "    for datum in batch:\n",
    "        padded_vec = np.pad(np.array(datum[0]),\n",
    "                                pad_width=((0,batch_max_input_length-datum[1])),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        data_list.append(padded_vec)\n",
    "        \n",
    "        padded_vec = np.pad(np.array(datum[2]),\n",
    "                                pad_width=((0,batch_max_output_length-datum[3])),\n",
    "                                mode=\"constant\", constant_values=0)\n",
    "        label_list.append(padded_vec)\n",
    "        \n",
    "    ind_dec_order = np.argsort(train_length_list)[::-1]\n",
    "    data_list = np.array(data_list)[ind_dec_order]\n",
    "    train_length_list = np.array(train_length_list)[ind_dec_order]\n",
    "    label_list = np.array(label_list)[ind_dec_order]\n",
    "    label_length_list = np.array(label_length_list)[ind_dec_order]\n",
    "    \n",
    "    #print(type(np.array(data_list)),type(np.array(label_list)))\n",
    "    \n",
    "    return [torch.from_numpy(np.array(data_list)).to(device), \n",
    "            torch.LongTensor(train_length_list).to(device), \n",
    "            torch.from_numpy(np.array(label_list)).to(device), \n",
    "            torch.LongTensor(label_length_list).to(device)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build train, valid and test dataloaders\n",
    "\n",
    "batch_size = 10 \n",
    "\n",
    "train_dataset = VocabDataset(train_input_index,train_output_index)\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           collate_fn=vocab_collate_func,\n",
    "                                           shuffle=False)\n",
    "\n",
    "# val_dataset = VocabDataset(val_data)\n",
    "# val_loader = torch.utils.data.DataLoader(dataset=val_dataset,\n",
    "#                                            batch_size=BATCH_SIZE,\n",
    "#                                            collate_fn=vocab_collate_func,\n",
    "#                                            shuffle=True)\n",
    "\n",
    "# test_dataset = VocabDataset(test_data)\n",
    "# test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "#                                            batch_size=BATCH_SIZE,\n",
    "#                                            collate_fn=vocab_collate_func,\n",
    "#                                            shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 49])\n",
      "tensor([49, 34, 30, 17, 17, 16, 11,  9,  9,  6])\n",
      "torch.Size([10, 46])\n",
      "tensor([46, 27, 18, 12, 13, 11, 11,  8,  9,  7])\n"
     ]
    }
   ],
   "source": [
    "for data, data_lengths, labels, label_lengths in train_loader:\n",
    "    print(data.shape)\n",
    "    print(data_lengths)\n",
    "    print(labels.shape)\n",
    "    print(label_lengths)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embed_size, hidden_size, num_direction):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_direction = num_direction\n",
    "        self.embedding = nn.Embedding(vocab_size, embed_size)\n",
    "        if num_direction == 1:\n",
    "            self.gru = nn.GRU(embed_size, hidden_size, batch_first=True)\n",
    "        elif num_direction == 2:\n",
    "            self.gru = nn.GRU(embed_size, hidden_size, batch_first=True, bidirectional = True)\n",
    "        else:\n",
    "            print('number of direction out of bound')\n",
    "\n",
    "    def forward(self, x, hidden, lengths):\n",
    "        embed = self.embedding(x)\n",
    "        embed = torch.nn.utils.rnn.pack_padded_sequence(embed, lengths.numpy(), batch_first=True)\n",
    "        rnn_out, hidden = self.gru(embed, hidden)\n",
    "        rnn_out, _ = torch.nn.utils.rnn.pad_packed_sequence(rnn_out, batch_first=True)\n",
    "        return rnn_out, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        hidden = torch.randn(self.num_direction, batch_size, self.hidden_size, device=device)\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, vocab_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, batch_first=True)\n",
    "        self.out = nn.Linear(hidden_size, vocab_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, src_input, hidden):\n",
    "        output = self.embedding(src_input)\n",
    "        #print(output.size())\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        logits = self.out(output[:,0,:])\n",
    "        output = self.softmax(logits)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self, batch_size):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0\n",
    "max_length_src = 50\n",
    "max_length_tgt = 50\n",
    "\n",
    "def train(input_tensor, input_lengths, target_tensor, target_lengths,\n",
    "          encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, \n",
    "          batch_size, max_length_src):\n",
    "\n",
    "    encoder_hidden = encoder.initHidden(batch_size)\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length_src, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "#     for ei in range(input_length):\n",
    "#         encoder_output, encoder_hidden = encoder(\n",
    "#             input_tensor[ei], encoder_hidden,input_tensor_length)\n",
    "#         encoder_outputs[ei] = encoder_output[0, 0]\n",
    "    encoder_output, encoder_hidden = encoder(input_tensor, encoder_hidden, input_lengths)\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]*batch_size], device=device).transpose(0,1)\n",
    "    decoder_hidden = encoder_hidden\n",
    "    \n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        target_lengths = target_lengths.numpy()\n",
    "        sent_not_end_index = list(range(batch_size))\n",
    "        decoding_token_index = 0\n",
    "        while len(sent_not_end_index) > 0:\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            sent_not_end_index = torch.LongTensor(sent_not_end_index).to(device)\n",
    "            loss += criterion(decoder_output.index_select(0,sent_not_end_index), \n",
    "                              target_tensor[:,decoding_token_index].index_select(\n",
    "                                  0,sent_not_end_index))\n",
    "            decoder_input = target_tensor[:,decoding_token_index].unsqueeze(1)  # Teacher forcing\n",
    "            decoding_token_index += 1\n",
    "            end_or_not = target_lengths > decoding_token_index\n",
    "            sent_not_end_index = list(np.where(end_or_not)[0])\n",
    "            \n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        target_lengths = target_lengths.numpy()\n",
    "        sent_not_end_index = list(range(batch_size))\n",
    "        decoding_token_index = 0\n",
    "        while len(sent_not_end_index) > 0:\n",
    "            decoder_output, decoder_hidden = decoder(\n",
    "                decoder_input, decoder_hidden)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.detach()  # detach from history as input\n",
    "            #print(type(sent_not_end_index[0]))\n",
    "            sent_not_end_index = torch.LongTensor(sent_not_end_index).to(device)\n",
    "            loss += criterion(decoder_output.index_select(0,sent_not_end_index), \n",
    "                              target_tensor[:,decoding_token_index].index_select(\n",
    "                                  0,sent_not_end_index))\n",
    "            decoding_token_index += 1\n",
    "            end_or_not = (target_lengths > decoding_token_index)*(\n",
    "                decoder_input.squeeze().numpy() != EOS_token)\n",
    "            sent_not_end_index = list(np.where(end_or_not)[0])\n",
    "            \n",
    "\n",
    "    loss.backward()\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(loader, encoder, decoder, n_iters = 340000, print_every=1000, \n",
    "               plot_every=100, learning_rate=0.01):\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "\n",
    "    criterion = nn.NLLLoss()\n",
    "    n_iter = 0\n",
    "    \n",
    "    for input_tensor, input_lengths, target_tensor, target_lengths in train_loader:\n",
    "        n_iter += 1\n",
    "        loss = train(input_tensor, input_lengths, target_tensor, target_lengths, \n",
    "                     encoder, decoder, encoder_optimizer, decoder_optimizer, \n",
    "                     criterion, batch_size, max_length_src)\n",
    "            \n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if n_iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('(%d %d%%) %.4f' % (n_iter, n_iter / n_iter * 100, print_loss_avg))\n",
    "\n",
    "        if n_iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-128-5392e699c3a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mencoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEncoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0memb_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_direction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDecoderRNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrainIters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_every\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-127-521e9c52edb0>\u001b[0m in \u001b[0;36mtrainIters\u001b[0;34m(loader, encoder, decoder, n_iters, print_every, plot_every, learning_rate)\u001b[0m\n\u001b[1;32m     15\u001b[0m         loss = train(input_tensor, input_lengths, target_tensor, target_lengths, \n\u001b[1;32m     16\u001b[0m                      \u001b[0mencoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m                      criterion, batch_size, max_length_src)\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mprint_loss_total\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-126-156c749588c6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(input_tensor, input_lengths, target_tensor, target_lengths, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, batch_size, max_length_src)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0mencoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mdecoder_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m     91\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \"\"\"\n\u001b[0;32m---> 93\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     94\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     88\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     89\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_size = enLang.n_words\n",
    "emb_size = 300\n",
    "hidden_size = 100\n",
    "num_direction = 1\n",
    "output_size = zhLang.n_words\n",
    "encoder = EncoderRNN(input_size, emb_size,hidden_size,num_direction = 1)\n",
    "decoder = DecoderRNN(hidden_size, output_size)\n",
    "trainIters(train_loader,encoder, decoder, 3, print_every=1000, plot_every=100, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.switch_backend('agg')\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import time\n",
    "# import math\n",
    "\n",
    "\n",
    "# def asMinutes(s):\n",
    "#     m = math.floor(s / 60)\n",
    "#     s -= m * 60\n",
    "#     return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "# def timeSince(since, percent):\n",
    "#     now = time.time()\n",
    "#     s = now - since\n",
    "#     es = s / (percent)\n",
    "#     rs = es - s\n",
    "#     return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
